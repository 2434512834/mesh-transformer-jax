{
  "layers": 24,
  "d_model": 2048,
  "n_heads": 16,
  "n_vocab": 50400,
  "norm": "layernorm",

  "seq": 1024,
  "cores_per_replica": 8,
  "per_replica_batch": 8,
  "gradient_accumulation_steps": 1,

  "warmup_steps": 1000,
  "anneal_steps": 100000,
  "lr": 1e-4,
  "end_lr": 1e-5,
  "weight_decay": 0.1,
  "total_steps": 100000,

  "tpu_size": 128,

  "bucket": "neo-models",
  "model_dir": "mesh_jax_owt_xl",

  "train_set": "openwebtext2_new_inputs.train.index",
  "val_set": "openwebtext2_new_inputs.val.index",

  "val_batches": 100,
  "val_every": 1000,
  "ckpt_every": 1000,

  "name": "GPT3_XL",
  "comment": "something similar to the OpenAI GPT3-XL in architecture, slightly different with heads and training schedule, for use on a V3-128"
}